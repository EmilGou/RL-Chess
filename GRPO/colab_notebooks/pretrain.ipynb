{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jwofW7iFLza",
        "outputId": "15c9e13c-5fed-4773-a32e-4ae41a3fa797"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.0' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/local/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install python-chess cairosvg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbpVvFuKgXRG",
        "outputId": "a93025e4-5512-4054-d12b-d1d51d33bf5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1BSBuF2dKOnVWuR5CNjp-o7QBYb-10JTO\n",
            "From (redirected): https://drive.google.com/uc?id=1BSBuF2dKOnVWuR5CNjp-o7QBYb-10JTO&confirm=t&uuid=29340ce8-569d-4e9a-9db8-601312ea8bbe\n",
            "To: /content/moves\n",
            "100% 134M/134M [00:01<00:00, 74.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q gdown\n",
        "FILE_ID=\"1BSBuF2dKOnVWuR5CNjp-o7QBYb-10JTO\"\n",
        "!gdown --id $FILE_ID -O moves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUBcv7rfhLO9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBYnrX1aVOMN"
      },
      "outputs": [],
      "source": [
        "path = \"/content/moves\"\n",
        "\n",
        "moves = open(path, \"r\").read()\n",
        "moves = moves.split('\\n\\n')[:-1]\n",
        "GAMES = [m.split('\\n')[:-1] for m in moves]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARDeRH3Aa_G6"
      },
      "outputs": [],
      "source": [
        "from GRPO.data import ChessGameDataset, untokenize, SPECIAL_TOKENS\n",
        "from GRPO.model import AutoregressiveTransformer\n",
        "from GRPO.pretrain.utils import sample_game_masked, sample_game_to_video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zy0TprDuIvWQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "n = len(GAMES)\n",
        "indices = list(range(n))\n",
        "random.shuffle(indices)\n",
        "split = int(n * 0.8)\n",
        "train_idx, test_idx = indices[:split], indices[split:]\n",
        "\n",
        "train_games = [GAMES[i] for i in train_idx]\n",
        "test_games  = [GAMES[i] for i in test_idx]\n",
        "\n",
        "max_len = 196\n",
        "train_ds = ChessGameDataset(train_games, max_seq_len=max_len)\n",
        "test_ds  = ChessGameDataset(test_games,  max_seq_len=max_len)\n",
        "\n",
        "bsz = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=bsz, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=bsz, shuffle=False)\n",
        "debug_display = False\n",
        "\n",
        "if debug_display:\n",
        "  for idx, (batch, labels) in enumerate(train_loader):\n",
        "      print(batch[0], labels[0])\n",
        "      print(\"Decoded batch:\")\n",
        "      print(untokenize(batch[0].tolist()))\n",
        "      print(\"Decoded labels:\")\n",
        "      print(untokenize(labels[0].tolist()))\n",
        "      if idx == 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UghmukxXcK-g",
        "outputId": "de0304e2-3a65-4bcc-840f-3672d7ac7d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 105145344\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AutoregressiveTransformer(\n",
              "  (token_emb): Embedding(2008, 1024)\n",
              "  (pos_emb): Embedding(257, 1024)\n",
              "  (transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-7): 8 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=2008, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "vocab_size = max(SPECIAL_TOKENS.values()) + 1\n",
        "model = AutoregressiveTransformer(vocab_size=vocab_size, pad_id=SPECIAL_TOKENS['<pad>'], d_model=1_024, d_ff=4_096, num_layers=8, max_len=256+1).cuda()\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "start_epoch = 0\n",
        "c = 0\n",
        "for pp in model.parameters():\n",
        "    c += pp.numel()\n",
        "print(\"Total parameters:\", c)\n",
        "\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "214NmPScgj7i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_DIR = '/content/checkpoints/'\n",
        "name = 'v1'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UfPigD18czPc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_ckpt(model, optimizer, path, device='cuda'):\n",
        "  ckpt = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "  model.load_state_dict(ckpt['model_state'], strict=True)\n",
        "  optimizer.load_state_dict(ckpt['opt_state'])\n",
        "  start_epoch = ckpt['epoch'] + 1\n",
        "  last_loss   = ckpt['loss']\n",
        "\n",
        "  model.to(device)\n",
        "  return model, optimizer, start_epoch, last_loss\n",
        "\n",
        "\n",
        "#CHECKPOINT_PATH = f\"{CHECKPOINT_DIR}/chess_v1_vocab_size=2008_pad_id=2006_d_model=1_024_d_ff=4_096_num_layers=8_epoch=35.pt\"\n",
        "#model, optimizer, start_epoch, last_loss = load_ckpt(model, optimizer, CHECKPOINT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Adh8gl-ksAq"
      },
      "outputs": [],
      "source": [
        "for epoch in range(start_epoch,100):\n",
        "    for step, (x, y) in enumerate(train_loader):\n",
        "        x = x.cuda(); y = y.cuda()\n",
        "        input_seq = x[:, :-1]\n",
        "        target_seq = y[:, 1:]\n",
        "\n",
        "        logits = model(input_seq)\n",
        "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq.reshape(-1), ignore_index=SPECIAL_TOKENS['<pad>'])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Epoch {epoch} Step {step} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "        if step % 500 == 0:\n",
        "          print('No masking:')\n",
        "          _ = sample_game_to_video(model, max_moves=200, frame_duration=0.5, top_k=5)\n",
        "          print(\"Masking:\")\n",
        "          _ = sample_game_masked(model,\n",
        "                       max_moves=100,\n",
        "                       temperature=1.0,\n",
        "                       frame_duration=0.5,\n",
        "                       video_path=\"chess_masked.mp4\")\n",
        "\n",
        "\n",
        "    CHECKPOINT_PATH = f'{CHECKPOINT_DIR}/chess_{name}_vocab_size={vocab_size}_pad_id={SPECIAL_TOKENS[\"<pad>\"]}_d_model=1_024_d_ff=4_096_num_layers=8_latest.pt'\n",
        "    torch.save({\n",
        "        'epoch':      epoch,\n",
        "        'model_state': model.state_dict(),\n",
        "        'opt_state':  optimizer.state_dict(),\n",
        "        'loss':       loss,\n",
        "    }, CHECKPOINT_PATH)\n",
        "    print(f\"Checkpoint saved to {CHECKPOINT_PATH}\")\n",
        "    if epoch % 5 == 0:\n",
        "      CHECKPOINT_PATH = f'{CHECKPOINT_DIR}/chess_{name}_vocab_size={vocab_size}_pad_id={SPECIAL_TOKENS[\"<pad>\"]}_d_model=1_024_d_ff=4_096_num_layers=8_epoch={epoch}.pt'\n",
        "      torch.save({\n",
        "          'epoch':      epoch,\n",
        "          'model_state': model.state_dict(),\n",
        "          'opt_state':  optimizer.state_dict(),\n",
        "          'loss':       loss,\n",
        "      }, CHECKPOINT_PATH)\n",
        "      print(f\"Checkpoint saved to {CHECKPOINT_PATH}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
