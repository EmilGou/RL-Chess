{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eK2Loh1hkiRl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jwofW7iFLza"
      },
      "outputs": [],
      "source": [
        "!pip install python-chess cairosvg\n",
        "!git clone https://github.com/EmilGou/RL-Chess.git\n",
        "%cd RL-Chess/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbpVvFuKgXRG"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q gdown\n",
        "FILE_ID=\"1BSBuF2dKOnVWuR5CNjp-o7QBYb-10JTO\"\n",
        "!gdown --id $FILE_ID -O moves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IUBcv7rfhLO9"
      },
      "outputs": [],
      "source": [
        "from GRPO.data import ChessGameDataset\n",
        "from GRPO.tokenize import SPECIAL_TOKENS, untokenize\n",
        "from GRPO.model import AutoregressiveTransformer, ChessConfig\n",
        "from GRPO.pretrain.utils import sample_game_masked, sample_game_to_video\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nBYnrX1aVOMN"
      },
      "outputs": [],
      "source": [
        "path = \"/content/moves\"\n",
        "\n",
        "moves = open(path, \"r\").read()\n",
        "moves = moves.split('\\n\\n')[:-1]\n",
        "GAMES = [m.split('\\n')[:-1] for m in moves]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zy0TprDuIvWQ"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "n = len(GAMES)\n",
        "indices = list(range(n))\n",
        "random.shuffle(indices)\n",
        "split = int(n * 0.8)\n",
        "train_idx, test_idx = indices[:split], indices[split:]\n",
        "\n",
        "train_games = [GAMES[i] for i in train_idx]\n",
        "test_games  = [GAMES[i] for i in test_idx]\n",
        "\n",
        "max_len = 196\n",
        "train_ds = ChessGameDataset(train_games, max_seq_len=max_len)\n",
        "test_ds  = ChessGameDataset(test_games,  max_seq_len=max_len)\n",
        "\n",
        "bsz = 32\n",
        "train_loader = DataLoader(train_ds, batch_size=bsz, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=bsz, shuffle=False)\n",
        "debug_display = False\n",
        "\n",
        "if debug_display:\n",
        "  for idx, (batch, labels) in enumerate(train_loader):\n",
        "      print(batch[0], labels[0])\n",
        "      print(\"Decoded batch:\")\n",
        "      print(untokenize(batch[0].tolist()))\n",
        "      print(\"Decoded labels:\")\n",
        "      print(untokenize(labels[0].tolist()))\n",
        "      if idx == 1:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UghmukxXcK-g"
      },
      "outputs": [],
      "source": [
        "vocab_size = max(SPECIAL_TOKENS.values()) + 1\n",
        "\n",
        "config = ChessConfig()\n",
        "config.vocab_size = vocab_size\n",
        "config.pad_id = SPECIAL_TOKENS['<pad>']\n",
        "config.d_model = 1_024\n",
        "config.d_ff = 4_096\n",
        "config.num_layers = 8\n",
        "config.max_len = 256 + 1\n",
        "\n",
        "\n",
        "model = AutoregressiveTransformer(config).cuda()\n",
        "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
        "start_epoch = 0\n",
        "c = 0\n",
        "for pp in model.parameters():\n",
        "    c += pp.numel()\n",
        "print(\"Total parameters:\", c)\n",
        "\n",
        "CHECKPOINT_DIR = '/content/checkpoints/'\n",
        "name = 'v1'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UfPigD18czPc"
      },
      "outputs": [],
      "source": [
        "def load_ckpt(model, optimizer, path, device='cuda'):\n",
        "  ckpt = torch.load(CHECKPOINT_PATH, map_location=device)\n",
        "  model.load_state_dict(ckpt['model_state'], strict=True)\n",
        "  optimizer.load_state_dict(ckpt['opt_state'])\n",
        "  start_epoch = ckpt['epoch'] + 1\n",
        "  last_loss   = ckpt['loss']\n",
        "\n",
        "  model.to(device)\n",
        "  return model, optimizer, start_epoch, last_loss\n",
        "\n",
        "#CHECKPOINT_PATH = f\"{CHECKPOINT_DIR}/chess_v1_vocab_size=2008_pad_id=2006_d_model=1_024_d_ff=4_096_num_layers=8_epoch=35.pt\"\n",
        "#model, optimizer, start_epoch, last_loss = load_ckpt(model, optimizer, CHECKPOINT_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Adh8gl-ksAq"
      },
      "outputs": [],
      "source": [
        "for epoch in range(start_epoch,100):\n",
        "    for step, (x, y) in enumerate(train_loader):\n",
        "        x = x.cuda(); y = y.cuda()\n",
        "        input_seq = x[:, :-1]\n",
        "        target_seq = y[:, 1:]\n",
        "\n",
        "        logits = model(input_seq)\n",
        "        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq.reshape(-1), ignore_index=SPECIAL_TOKENS['<pad>'])\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 100 == 0:\n",
        "            print(f\"Epoch {epoch} Step {step} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "        if step % 500 == 0:\n",
        "          print('No masking:')\n",
        "          _ = sample_game_to_video(model, max_moves=200, frame_duration=0.5, top_k=5)\n",
        "          print(\"Masking:\")\n",
        "          _ = sample_game_masked(model,\n",
        "                       max_moves=100,\n",
        "                       temperature=1.0,\n",
        "                       frame_duration=0.5,\n",
        "                       video_path=\"chess_masked.mp4\")\n",
        "\n",
        "\n",
        "    CHECKPOINT_PATH = f'{CHECKPOINT_DIR}/chess_{name}_vocab_size={vocab_size}_pad_id={SPECIAL_TOKENS[\"<pad>\"]}_d_model=1_024_d_ff=4_096_num_layers=8_latest.pt'\n",
        "    torch.save({\n",
        "        'epoch':      epoch,\n",
        "        'model_state': model.state_dict(),\n",
        "        'opt_state':  optimizer.state_dict(),\n",
        "        'loss':       loss,\n",
        "    }, CHECKPOINT_PATH)\n",
        "    print(f\"Checkpoint saved to {CHECKPOINT_PATH}\")\n",
        "    if epoch % 5 == 0:\n",
        "      CHECKPOINT_PATH = f'{CHECKPOINT_DIR}/chess_{name}_vocab_size={vocab_size}_pad_id={SPECIAL_TOKENS[\"<pad>\"]}_d_model=1_024_d_ff=4_096_num_layers=8_epoch={epoch}.pt'\n",
        "      torch.save({\n",
        "          'epoch':      epoch,\n",
        "          'model_state': model.state_dict(),\n",
        "          'opt_state':  optimizer.state_dict(),\n",
        "          'loss':       loss,\n",
        "      }, CHECKPOINT_PATH)\n",
        "      print(f\"Checkpoint saved to {CHECKPOINT_PATH}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}