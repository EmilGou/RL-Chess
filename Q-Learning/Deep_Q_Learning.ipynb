{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install chess\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "from collections import namedtuple, deque\n",
        "import chess\n",
        "import chess.svg\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "UkcCBwu5pxgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4080ea-8d2c-407b-9fe6-7637948dfc66"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chess in /usr/local/lib/python3.11/dist-packages (1.11.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting device\n",
        "device = torch.device(\n",
        "    \"cuda\" if torch.cuda.is_available() else\n",
        "    \"mps\" if torch.backends.mps.is_available() else\n",
        "    \"cpu\"\n",
        ")"
      ],
      "metadata": {
        "id": "d20o_hjkp-F3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Q_uy7AhvQINX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size,\n",
        "                              stride=stride, padding=padding)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Shortcut connection for dimension matching\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
        "                         stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += residual  # Add residual connection\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ghUK17a4pzs-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block = ResidualBlock(3, 16, 3)\n",
        "test = torch.rand((1, 3, 64, 64))\n",
        "block(test).shape"
      ],
      "metadata": {
        "id": "m6zq7N-q8rki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e785666d-f7d5-4918-a115-c58bbb375ac2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            ResidualBlock(in_channels, 32, 3),\n",
        "            ResidualBlock(32, 32, 3),\n",
        "            ResidualBlock(32, 64, 3),\n",
        "            ResidualBlock(64, 64, 3),\n",
        "            ResidualBlock(64, 128, 3),\n",
        "            ResidualBlock(128, 128, 3),\n",
        "            ResidualBlock(128, 73, 3),\n",
        "            nn.Conv2d(73, 73, kernel_size=3,    # output head\n",
        "                      stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cB6Ddhy_6OBS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = DQN(19)\n",
        "test = torch.rand((10, 19, 8, 8))\n",
        "test_out = test_model(test)\n",
        "test_out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDeD-Mm1Fxhw",
        "outputId": "2a94c51a-f328-4f02-dc50-8fa18e01ad2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 73, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Replay Memory"
      ],
      "metadata": {
        "id": "uinc3CfP6sLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Transition = namedtuple('Transition',\n",
        "                        ('turn', 'state', 'action', 'next_fen', 'next_state', 'terminal', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "    def __init__(self, capacity, batch_size):\n",
        "        self.capacity = capacity\n",
        "        self.memory = deque([], maxlen=self.capacity)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def extend(self, list_of_transitions):\n",
        "        self.memory.extend(list_of_transitions)\n",
        "\n",
        "    def sample(self, batch_size=None):\n",
        "        if batch_size is None:\n",
        "          return random.sample(self.memory, self.batch_size)\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "metadata": {
        "id": "cpR8LwQn6uGD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rm = ReplayMemory(10000, 8)\n",
        "data = [Transition(*list(range(7)))] * 10\n",
        "rm.extend(data)\n",
        "transitions = rm.sample(5)\n",
        "batch = Transition(*zip(*transitions))"
      ],
      "metadata": {
        "id": "CPOjYF8a57qn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch.turn"
      ],
      "metadata": {
        "id": "yfDj7HRb5_lm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586c8a46-d792-417d-b655-2d91eb79e1db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class of Helper Functions That Connect Model to Chess Board"
      ],
      "metadata": {
        "id": "Zo6aJHSbsXM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChessHelper():\n",
        "  def __init__(self, step_history=5):\n",
        "    # Calculates shape of tensor for current board state\n",
        "    board_size = 8\n",
        "    planes_for_pieces = 2*6 + 1\n",
        "    planes_for_rules = 1 + 4 + 1\n",
        "    amount_of_input_planes =  planes_for_rules + planes_for_pieces\n",
        "    self.input_shape = (amount_of_input_planes, board_size, board_size)\n",
        "    # Tracks how many previous moves the model should account for\n",
        "    self.step_history = step_history\n",
        "    history_planes = step_history*planes_for_pieces\n",
        "    self.history_input = (history_planes,board_size,board_size)\n",
        "    self.white_history = torch.zeros(self.history_input)\n",
        "    self.black_history = torch.zeros(self.history_input)\n",
        "\n",
        "    # Maps channels of model output to moves and promotions\n",
        "    # Format: (Δcol, Δrow, promotion) where promotion=0 means no promotion according to row and column of output tensor\n",
        "    self.channel_map = self.fill_channel_map()\n",
        "\n",
        "  def fill_channel_map(self):\n",
        "    \"\"\"\n",
        "    Maps each of the 73 channels of model output to a specific move and promotion.\n",
        "    \"\"\"\n",
        "    channel_map = []\n",
        "    # Directions: (Δcol, Δrow)\n",
        "    queen_directions = [\n",
        "      (-1, 1),  # Up-Left\n",
        "      (0, 1),   # Up\n",
        "      (1, 1),   # Up-Right\n",
        "      (1, 0),   # Right\n",
        "      (1, -1),  # Down-Right\n",
        "      (0, -1),  # Down\n",
        "      (-1, -1),  # Down-Left\n",
        "      (-1, 0)  # Left\n",
        "    ]\n",
        "\n",
        "    # Generate queen moves\n",
        "    for dc, dr in queen_directions:\n",
        "      for distance in range(1, 8):  # 1 to 7 squares\n",
        "        channel_map.append([dc * distance, dr * distance, 0])\n",
        "\n",
        "    # Knight move offsets\n",
        "    knight_moves = [\n",
        "      (-1, 2),   # Up-Left\n",
        "      (1, 2),   # Up-Right\n",
        "      (2, 1),   # Right-Up\n",
        "      (2, -1),  # Right-Down\n",
        "      (1, -2),  # Down-Right\n",
        "      (-1, -2), # Down-Left\n",
        "      (-2, -1), # Left-Down\n",
        "      (-2, 1)  # Left-Up\n",
        "    ]\n",
        "\n",
        "    # Generate knight moves\n",
        "    for dc, dr in knight_moves:\n",
        "      channel_map.append([dc, dr, 0])\n",
        "\n",
        "    # Underpromotion moves\n",
        "    underpromotion_moves = [\n",
        "      (-1, 1),  # Capture left\n",
        "      (0, 1),   # Forward\n",
        "      (1, 1)   # Capture right\n",
        "    ]\n",
        "\n",
        "    # Promotion piece types\n",
        "    promotion_pieces = [chess.KNIGHT, chess.BISHOP, chess.ROOK]\n",
        "\n",
        "    # Generate underpromotion moves\n",
        "    for promo in promotion_pieces:\n",
        "      for dc, dr in underpromotion_moves:\n",
        "        channel_map.append([dc, dr, promo])\n",
        "\n",
        "    return torch.tensor(channel_map, dtype=torch.int16)\n",
        "\n",
        "  # TODO: credit wherever we got this code from\n",
        "  def board_state_to_input(self, fen: str):\n",
        "    \"\"\"\n",
        "    Convert board to a state that is interpretable by the model. Flip's the board on black's turn.\n",
        "    \"\"\"\n",
        "\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    # 1. is it white's turn? (1x8x8)\n",
        "    is_white_turn = torch.ones((8, 8)) if board.turn else torch.zeros((8, 8))\n",
        "\n",
        "    # 2. castling rights (4x8x8)\n",
        "    castling = torch.stack([\n",
        "        torch.ones((8, 8)) if board.has_queenside_castling_rights(\n",
        "            chess.WHITE) else torch.zeros((8, 8)),\n",
        "        torch.ones((8, 8)) if board.has_kingside_castling_rights(\n",
        "            chess.WHITE) else torch.zeros((8, 8)),\n",
        "        torch.ones((8, 8)) if board.has_queenside_castling_rights(\n",
        "            chess.BLACK) else torch.zeros((8, 8)),\n",
        "        torch.ones((8, 8)) if board.has_kingside_castling_rights(\n",
        "            chess.BLACK) else torch.zeros((8, 8)),\n",
        "    ])\n",
        "\n",
        "    # 3. repitition counter\n",
        "    counter = torch.ones(\n",
        "        (8, 8)) if board.can_claim_fifty_moves() else torch.zeros((8, 8))\n",
        "\n",
        "    # create new torch array\n",
        "    arrays = []\n",
        "    # tracking the order of the tensor\n",
        "    order = []\n",
        "    if board.turn:\n",
        "      order = chess.COLORS\n",
        "    else:\n",
        "      order = [False,True]\n",
        "\n",
        "    for color in order:\n",
        "        # 4. player 1's pieces (6x8x8)\n",
        "        # 5. player 2's pieces (6x8x8)\n",
        "        for piece_type in chess.PIECE_TYPES:\n",
        "            # 6 arrays of 8x8 booleans\n",
        "            array = torch.zeros((8, 8))\n",
        "            for index in list(board.pieces(piece_type, color)):\n",
        "                # row calculation: 7 - index/8 because we want to count from bottom left, not top left\n",
        "                if board.turn:\n",
        "                  array[7 - int(index/8)][index % 8] = True\n",
        "                else:\n",
        "                  array[int(index/8)][7 - index % 8] = True\n",
        "            arrays.append(array)\n",
        "    arrays = torch.stack(arrays)\n",
        "\n",
        "    # 6. en passant square (8x8)\n",
        "    en_passant = torch.zeros((8, 8))\n",
        "    if board.has_legal_en_passant():\n",
        "        en_passant[7 - int(board.ep_square/8)][board.ep_square % 8] = True\n",
        "\n",
        "    r = torch.stack([is_white_turn, *castling,\n",
        "                counter, *arrays, en_passant]).reshape((1, *self.input_shape))\n",
        "    # memory management\n",
        "    del board\n",
        "    return r.float()\n",
        "\n",
        "  def masker(self, output_tensor, board_fen):\n",
        "      board = chess.Board(board_fen)\n",
        "\n",
        "      #If it is white we make a mask of -infinity, if black we set mask to positive infinity\n",
        "      if board.turn:\n",
        "          mask = torch.full_like(output_tensor, float('-inf'))\n",
        "      else:\n",
        "          mask = torch.full_like(output_tensor, float('inf'))\n",
        "\n",
        "      # converting legal moves to the form (delta file, delta rank, promotion, from_square_rank, and from_square_file)\n",
        "      legal_moves = []\n",
        "      for move in board.legal_moves:\n",
        "        from_file = chess.square_file(move.from_square)\n",
        "        from_rank = chess.square_rank(move.from_square)\n",
        "        to_file = chess.square_file(move.to_square)\n",
        "        to_rank = chess.square_rank(move.to_square)\n",
        "\n",
        "        # Converting rank and file to row and column index in output tensor\n",
        "        if board.turn:\n",
        "          from_row = 7 - from_rank\n",
        "          from_col = from_file\n",
        "          to_row = 7 - to_rank\n",
        "          to_col = to_file\n",
        "        else:\n",
        "          from_row = from_rank\n",
        "          from_col = 7 - from_file\n",
        "          to_row = to_rank\n",
        "          to_col = 7 - to_file\n",
        "\n",
        "        dc = to_col - from_col\n",
        "        dr = from_row - to_row\n",
        "        promo = move.promotion if move.promotion else 0\n",
        "        # In channel map, queen promotions are counted as regular queen moves\n",
        "        if promo == chess.QUEEN:\n",
        "          promo = 0\n",
        "\n",
        "        legal_moves.append((dc, dr, promo, from_col, from_row))\n",
        "\n",
        "      # if no legal moves... all infinity\n",
        "      if not legal_moves:\n",
        "        return output_tensor + mask\n",
        "\n",
        "      # Track legal moves\n",
        "      move_tensor = torch.tensor(legal_moves, dtype=torch.int16)\n",
        "      move_deltas = move_tensor[:, :3]\n",
        "\n",
        "      # Compare against all 73 channels via broadcasting\n",
        "      delta_diff = move_deltas[:, None, :] == self.channel_map[None, :, :]  # (N, 73, 3)\n",
        "      matches = delta_diff.all(dim=2)  # (N, 73)\n",
        "      move_indexs, channel_indexs = matches.nonzero(as_tuple=True)\n",
        "\n",
        "      # Convert these to long for indexing\n",
        "      col_indexs = move_tensor[move_indexs, 3].long()\n",
        "      row_indexs = move_tensor[move_indexs, 4].long()\n",
        "      channel_indexs = channel_indexs.long()\n",
        "\n",
        "      # Set mask to 0 for legal moves\n",
        "      mask[0, channel_indexs, row_indexs, col_indexs] = 0.0\n",
        "\n",
        "      return output_tensor + mask\n",
        "\n",
        "  def board_state(self,fen:str):\n",
        "\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    # create new torch array\n",
        "    arrays = []\n",
        "    # tracking the order of the tensor\n",
        "    order = []\n",
        "    if board.turn:\n",
        "      order = chess.COLORS\n",
        "    else:\n",
        "      order = [False,True]\n",
        "\n",
        "    for color in order:\n",
        "        # 4. player 1's pieces (6x8x8)\n",
        "        # 5. player 2's pieces (6x8x8)\n",
        "        for piece_type in chess.PIECE_TYPES:\n",
        "            # 6 arrays of 8x8 booleans\n",
        "            array = torch.zeros((8, 8))\n",
        "            for index in list(board.pieces(piece_type, color)):\n",
        "                # row calculation: 7 - index/8 because we want to count from bottom left, not top left\n",
        "                if board.turn:\n",
        "                  array[7 - int(index/8)][index % 8] = True\n",
        "                else:\n",
        "                  array[int(index/8)][7 - index % 8] = True\n",
        "            arrays.append(array)\n",
        "    arrays = torch.stack(arrays)\n",
        "\n",
        "    # 6. en passant square (8x8)\n",
        "    en_passant = torch.zeros((8, 8))\n",
        "    if board.has_legal_en_passant():\n",
        "        en_passant[7 - int(board.ep_square/8)][board.ep_square % 8] = True\n",
        "\n",
        "    r = torch.stack([*arrays, en_passant]).reshape((13, 8, 8))\n",
        "    # memory management\n",
        "    del board\n",
        "    return r.float()\n",
        "\n",
        "\n",
        "  def add_to_history(self, fen):\n",
        "    #base case\n",
        "    if self.step_history == 0:\n",
        "        self.white_history = torch.empty((0,8,8))\n",
        "        self.black_history = torch.empty((0,8,8))\n",
        "        return  # No need to store history if step_history is 0\n",
        "\n",
        "    board = chess.Board(fen)\n",
        "    state = self.board_state(fen).squeeze(0)  # (13, 8, 8)\n",
        "\n",
        "    if board.turn:  # white to move\n",
        "      prev_history = self.white_history[13:]\n",
        "      if self.step_history > 1:\n",
        "        new_history = torch.cat([state,prev_history], dim = 0)[:self.history_input[0] - 13]\n",
        "      else:\n",
        "        new_history = torch.empty((0,8,8))\n",
        "      self.white_history = torch.cat([state, new_history], dim = 0)\n",
        "    else:  # black to move\n",
        "      prev_history = self.black_history[13:]\n",
        "      if self.step_history > 1:\n",
        "        new_history = torch.cat([state,prev_history], dim = 0)[:self.history_input[0] - 13]\n",
        "      else:\n",
        "        new_history = torch.empty((0,8,8))\n",
        "      self.black_history = torch.cat([state, new_history], dim = 0)\n",
        "\n",
        "  def concat_step_history(self, fen):\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    new_input = self.board_state_to_input(fen)\n",
        "    new_input = new_input.float()\n",
        "\n",
        "    if board.turn:\n",
        "      history = self.white_history.unsqueeze(0)\n",
        "    else:\n",
        "      history = self.black_history.unsqueeze(0)\n",
        "\n",
        "    if self.step_history == 0:\n",
        "      return new_input\n",
        "    else:\n",
        "      stacked = torch.cat([new_input, history], dim=1)\n",
        "      self.add_to_history(fen)\n",
        "      return stacked\n",
        "\n",
        "  def output_to_optimal_indices(self, output, fen):\n",
        "    \"\"\"\n",
        "    Takes output of model and gets the channel index, row, and column of the\n",
        "    maximum or minimum value, depending if it is white's or black's turn,\n",
        "    respectively.\n",
        "\n",
        "    Output: (channel, row, col)\n",
        "    \"\"\"\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    if board.turn == chess.WHITE:\n",
        "      flat_optimal_indices = output.flatten(start_dim=1).argmax(dim=1)\n",
        "    else:\n",
        "      flat_optimal_indices = output.flatten(start_dim=1).argmin(dim=1)\n",
        "    channel, row, col = torch.unravel_index(flat_optimal_indices, (73, 8, 8))\n",
        "\n",
        "    # Memory management\n",
        "    del board\n",
        "\n",
        "    return (channel.cpu(), row.cpu(), col.cpu())\n",
        "\n",
        "  def indices_to_move(self, fen, channel_indices, row_indices, col_indices):\n",
        "    \"\"\"\n",
        "    Takes indices to output of model and converts it to format for chess.Move\n",
        "\n",
        "    Input: Channel, row, and column indices corresponding to desired moves in model output\n",
        "    Output: (from_square: torch.tensor, to_square: torch.tensor, promotion: List)\n",
        "    \"\"\"\n",
        "    board = chess.Board(fen)\n",
        "\n",
        "    # Getting move delta and promotion info from channel index\n",
        "    move_details = self.channel_map[channel_indices]\n",
        "    dc, dr, promotion = move_details[:,0], move_details[:,1], move_details[:,2]\n",
        "\n",
        "    # Calculating new location of piece\n",
        "    to_col = col_indices + dc\n",
        "    to_row = row_indices - dr\n",
        "\n",
        "    # Converting from rows and cols to rank and file\n",
        "    if board.turn == chess.WHITE:\n",
        "      from_rank = 7 - row_indices\n",
        "      from_file = col_indices\n",
        "      to_rank = 7 - to_row\n",
        "      to_file = to_col\n",
        "    else:\n",
        "      # Black's perspective is flipped\n",
        "      from_rank = row_indices\n",
        "      from_file = 7 - col_indices\n",
        "      to_rank = to_row\n",
        "      to_file = 7 - to_col\n",
        "\n",
        "    # Changing from rank and file to square index\n",
        "    from_square = chess.square(from_file, from_rank)\n",
        "    to_square = chess.square(to_file, to_rank)\n",
        "\n",
        "    # Error catcher\n",
        "    if board.piece_at(from_square) is None:\n",
        "      print('\\n', board.fen(), '\\n')\n",
        "      print('channel, row, col', channel_indices, row_indices, col_indices, '\\n')\n",
        "      raise Exception('Error caught in indices_to_move.')\n",
        "\n",
        "    # Checking for pawn to queen promotion\n",
        "    if board.piece_at(from_square).piece_type == chess.PAWN and (to_rank == 0 or to_rank == 7):\n",
        "      promotion = torch.tensor([chess.QUEEN])\n",
        "\n",
        "    # Promotion=0 means no promotion\n",
        "    promotion = [p.item() if p != 0 else None for p in promotion]\n",
        "\n",
        "    # Memory management\n",
        "    del board\n",
        "\n",
        "    return (from_square, to_square, promotion)\n",
        "\n",
        "  def output_to_move(self, output, fen):\n",
        "    \"\"\"\n",
        "    Takes output of model, chooses the best move, and converts it to format for chess.Move.\n",
        "    Wrapper function for output_to_optimal_indices and indices_to_move.\n",
        "\n",
        "    Input: 1x73x8x8 tensor where each plane corresponds to a specific move\n",
        "    Output: (from_square: torch.tensor, to_square: torch.tensor, promotion: List)\n",
        "    \"\"\"\n",
        "    optimal_indices = self.output_to_optimal_indices(output, fen)\n",
        "    from_square, to_square, promotion = self.indices_to_move(fen, *optimal_indices)\n",
        "    return (from_square, to_square, promotion)\n",
        "\n",
        "  def move_to_index(self, turn, move):\n",
        "    # Getting starting and ending square for move\n",
        "    from_file = chess.square_file(move.from_square)\n",
        "    from_rank = chess.square_rank(move.from_square)\n",
        "    to_file = chess.square_file(move.to_square)\n",
        "    to_rank = chess.square_rank(move.to_square)\n",
        "\n",
        "    # Converting rank and file to row and column index in output tensor\n",
        "    if turn:\n",
        "      from_row = 7 - from_rank\n",
        "      from_col = from_file\n",
        "      to_row = 7 - to_rank\n",
        "      to_col = to_file\n",
        "    else:\n",
        "      from_row = from_rank\n",
        "      from_col = 7 - from_file\n",
        "      to_row = to_rank\n",
        "      to_col = 7 - to_file\n",
        "\n",
        "    # Getting move deltas and promotion\n",
        "    dc = to_col - from_col\n",
        "    dr = from_row - to_row\n",
        "    promotion = move.promotion if move.promotion in [chess.KNIGHT, chess.BISHOP, chess.ROOK] else 0\n",
        "    move_details = torch.tensor([dc, dr, promotion])\n",
        "\n",
        "    # Getting corresponding index of tensor from rank and file\n",
        "    channel_idx = torch.where((self.channel_map == move_details).all(dim=1))[0]\n",
        "\n",
        "    # Changing from_row and from_col to tensor to keep consistent index output\n",
        "    return channel_idx, torch.tensor([from_row]), torch.tensor([from_col])"
      ],
      "metadata": {
        "id": "79wJX8wq6tNa"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing History Function"
      ],
      "metadata": {
        "id": "YEn_38K_I4Jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking history functions\n",
        "chess_helper = ChessHelper(step_history=3)\n",
        "board = chess.Board()\n",
        "input = chess_helper.concat_step_history(board.fen())\n",
        "print(input.shape)\n",
        "# white pawns\n",
        "print(input[0, 6, :, :])\n",
        "# zero padding\n",
        "print(torch.all(input[0, 20:, :, :] == 0))"
      ],
      "metadata": {
        "id": "saJZINJjvziC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fa8583b-8210-4556-e548-e9467e0f324b"
      },
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 58, 8, 8])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "board.push(chess.Move.from_uci(\"e2e4\"))\n",
        "input2 = chess_helper.concat_step_history(board.fen())"
      ],
      "metadata": {
        "id": "0LerpUIxTqFL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# black pawns\n",
        "print(input2[0, 6, :, :])\n",
        "# zero padding\n",
        "print(torch.all(input2[0, 20:, :, :] == 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2LNRfxCGWZC",
        "outputId": "0bfabcea-b804-4770-821a-321afa87e742"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "board.push(chess.Move.from_uci(\"e7e5\"))\n",
        "input3 = chess_helper.concat_step_history(board.fen())"
      ],
      "metadata": {
        "id": "pjdhGHlxTpKr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "board"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "94N2_OcHViiZ",
        "outputId": "f49c482a-4750-4f22-e0f5-3bbfed832ace"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r n b q k b n r\np p p p . p p p\n. . . . . . . .\n. . . . p . . .\n. . . . P . . .\n. . . . . . . .\nP P P P . P P P\nR N B Q K B N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark lastmove e5\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark lastmove e7\" stroke=\"none\" fill=\"#aaa23b\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(150, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(240, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 150)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(60, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(285, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# white pawns\n",
        "print(input3[0, 6, :, :])\n",
        "print(input3[0, 19, :, :])\n",
        "# zero padding\n",
        "print(torch.all(input3[0, 32:, :, :] == 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjjwA6dNTQ-b",
        "outputId": "81af3415-6f51-45d9-a10d-e443605072d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor(False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input3[0, 32, :, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ6PRW6BT0ia",
        "outputId": "769de7cb-4d9d-488d-97ab-0d021938471c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking history functions\n",
        "chess_helper = ChessHelper(step_history=3)\n",
        "board = chess.Board()\n",
        "input = chess_helper.concat_step_history(board.fen())\n",
        "print(input.shape)\n",
        "# white pawns\n",
        "print(input[0, 6, :, :])\n",
        "# zero padding\n",
        "print(torch.all(input[0, 20:, :, :] == 0))"
      ],
      "metadata": {
        "id": "B3QWqw3GTFgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae26d99-77ce-462e-e8f5-3f8f3694aa67"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 58, 8, 8])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chess_helper.add_to_history(board.fen())\n",
        "# board.push(chess.Move.from_uci(\"e7e5\"))"
      ],
      "metadata": {
        "id": "15dTjm7vGYTE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Test Run ----\n",
        "helper = ChessHelper(step_history=1)\n",
        "\n",
        "fen1 = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
        "fen2 = \"rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR b KQkq - 0 1\"\n",
        "fen3 = \"rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq e6 0 2\"\n",
        "\n",
        "helper.add_to_history(fen1)\n",
        "helper.add_to_history(fen2)\n",
        "\n",
        "# Combine current board + history\n",
        "combined = helper.concat_step_history(fen3)\n",
        "\n",
        "print(\"Combined shape:\", combined.shape)"
      ],
      "metadata": {
        "id": "K1D00iRoEFuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aecd82ae-e462-4acd-e108-0de327297e64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined shape: torch.Size([1, 32, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "board = chess.Board()"
      ],
      "metadata": {
        "id": "3iG0_CdZv21Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chess_helper.concat_step_history(board.fen())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36G_suXXv362",
        "outputId": "f69ec815-a3c8-4db3-9c4c-9b1e09fdd445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
              "\n",
              "         [[1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          ...,\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.],\n",
              "          [1., 1., 1.,  ..., 1., 1., 1.]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
              "\n",
              "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          ...,\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "          [0., 0., 0.,  ..., 0., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Chess Helper Class"
      ],
      "metadata": {
        "id": "BGlMEejcImoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing board output\n",
        "board = chess.Board()\n",
        "chess_helper = ChessHelper()\n",
        "test_model = DQN(19)\n",
        "test = torch.rand((1, 19, 8, 8))\n",
        "test_out = test_model(test)\n",
        "test_out = chess_helper.masker(test_out, board.fen())\n",
        "print(f\"test output shape: {test_out.shape}\")\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "# Making sure that move_to_index and indices_to_move are inverses\n",
        "opt_indices = chess_helper.output_to_optimal_indices(test_out, chess.STARTING_FEN)\n",
        "print(opt_indices)\n",
        "move_details = chess_helper.indices_to_move(chess.STARTING_FEN, *opt_indices)\n",
        "print(move_details)\n",
        "move_details = move_details[:2] + (0,)\n",
        "returned_indices = chess_helper.move_to_index(board.turn, chess.Move(*move_details))\n",
        "print(returned_indices)#\n",
        "assert(opt_indices == returned_indices)\n",
        "print('--------------------------------------------------------------------')\n",
        "\n",
        "# Testing board_state_to_input\n",
        "fen = 'r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR b KQkq - 0 4'\n",
        "board = chess.Board(fen)\n",
        "input = chess_helper.board_state_to_input(fen)\n",
        "print(input.shape)\n",
        "# Showing black pawns (and orients to black player's perspective)\n",
        "print(input[0, 6, :, :])\n",
        "print('--------------------------------------------------------------------')\n",
        "board"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "1w-0nHyn-n73",
        "outputId": "5e7bf347-442b-4061-a5da-d7a6dfdd3adc"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test output shape: torch.Size([1, 73, 8, 8])\n",
            "--------------------------------------------------------------------\n",
            "(tensor([8]), tensor([6]), tensor([4]))\n",
            "(tensor([12]), tensor([28]), [None])\n",
            "(tensor([8]), tensor([6]), tensor([4]))\n",
            "--------------------------------------------------------------------\n",
            "torch.Size([1, 19, 8, 8])\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 1., 1., 1., 1.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
            "--------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Board('r1bqkb1r/pppp1Qpp/2n2n2/4p3/2B1P3/8/PPPP1PPP/RNB1K1NR b KQkq - 0 4')"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 390 390\" width=\"390\" height=\"390\"><desc><pre>r . b q k b . r\np p p p . Q p p\n. . n . . n . .\n. . . . p . . .\n. . B . P . . .\n. . . . . . . .\nP P P P . P P P\nR N B . K . N R</pre></desc><defs><g id=\"white-pawn\" class=\"white pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#fff\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"white-knight\" class=\"white knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#ffffff; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#000000; stroke:#000000;\" /></g><g id=\"white-bishop\" class=\"white bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#fff\" stroke-linecap=\"butt\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zM15 32c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" /></g><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke-linejoin=\"miter\" /></g><g id=\"white-rook\" class=\"white rook\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12 36v-4h21v4H12zM11 14V9h4v2h5V9h5v2h5V9h4v5\" stroke-linecap=\"butt\" /><path d=\"M34 14l-3 3H14l-3-3\" /><path d=\"M31 17v12.5H14V17\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M31 29.5l1.5 2.5h-20l1.5-2.5\" /><path d=\"M11 14h23\" fill=\"none\" stroke-linejoin=\"miter\" /></g><g id=\"white-queen\" class=\"white queen\" fill=\"#fff\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M8 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM24.5 7.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM41 12a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM16 8.5a2 2 0 1 1-4 0 2 2 0 1 1 4 0zM33 9a2 2 0 1 1-4 0 2 2 0 1 1 4 0z\" /><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2-12-7 11V11l-5.5 13.5-3-15-3 15-5.5-14V25L7 14l2 12zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11.5 30c3.5-1 18.5-1 22 0M12 33.5c6-1 15-1 21 0\" fill=\"none\" /></g><g id=\"white-king\" class=\"white king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#fff\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#fff\" /><path d=\"M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" /></g><g id=\"black-pawn\" class=\"black pawn\"><path d=\"M22.5 9c-2.21 0-4 1.79-4 4 0 .89.29 1.71.78 2.38C17.33 16.5 16 18.59 16 21c0 2.03.94 3.84 2.41 5.03-3 1.06-7.41 5.55-7.41 13.47h23c0-7.92-4.41-12.41-7.41-13.47 1.47-1.19 2.41-3 2.41-5.03 0-2.41-1.33-4.5-3.28-5.62.49-.67.78-1.49.78-2.38 0-2.21-1.79-4-4-4z\" fill=\"#000\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" /></g><g id=\"black-knight\" class=\"black knight\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M 22,10 C 32.5,11 38.5,18 38,39 L 15,39 C 15,30 25,32.5 23,18\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 24,18 C 24.38,20.91 18.45,25.37 16,27 C 13,29 13.18,31.34 11,31 C 9.958,30.06 12.41,27.96 11,28 C 10,28 11.19,29.23 10,30 C 9,30 5.997,31 6,26 C 6,24 12,14 12,14 C 12,14 13.89,12.1 14,10.5 C 13.27,9.506 13.5,8.5 13.5,7.5 C 14.5,6.5 16.5,10 16.5,10 L 18.5,10 C 18.5,10 19.28,8.008 21,7 C 22,7 22,10 22,10\" style=\"fill:#000000; stroke:#000000;\" /><path d=\"M 9.5 25.5 A 0.5 0.5 0 1 1 8.5,25.5 A 0.5 0.5 0 1 1 9.5 25.5 z\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 15 15.5 A 0.5 1.5 0 1 1 14,15.5 A 0.5 1.5 0 1 1 15 15.5 z\" transform=\"matrix(0.866,0.5,-0.5,0.866,9.693,-5.173)\" style=\"fill:#ececec; stroke:#ececec;\" /><path d=\"M 24.55,10.4 L 24.1,11.85 L 24.6,12 C 27.75,13 30.25,14.49 32.5,18.75 C 34.75,23.01 35.75,29.06 35.25,39 L 35.2,39.5 L 37.45,39.5 L 37.5,39 C 38,28.94 36.62,22.15 34.25,17.66 C 31.88,13.17 28.46,11.02 25.06,10.5 L 24.55,10.4 z \" style=\"fill:#ececec; stroke:none;\" /></g><g id=\"black-bishop\" class=\"black bishop\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 36c3.39-.97 10.11.43 13.5-2 3.39 2.43 10.11 1.03 13.5 2 0 0 1.65.54 3 2-.68.97-1.65.99-3 .5-3.39-.97-10.11.46-13.5-1-3.39 1.46-10.11.03-13.5 1-1.354.49-2.323.47-3-.5 1.354-1.94 3-2 3-2zm6-4c2.5 2.5 12.5 2.5 15 0 .5-1.5 0-2 0-2 0-2.5-2.5-4-2.5-4 5.5-1.5 6-11.5-5-15.5-11 4-10.5 14-5 15.5 0 0-2.5 1.5-2.5 4 0 0-.5.5 0 2zM25 8a2.5 2.5 0 1 1-5 0 2.5 2.5 0 1 1 5 0z\" fill=\"#000\" stroke-linecap=\"butt\" /><path d=\"M17.5 26h10M15 30h15m-7.5-14.5v5M20 18h5\" stroke=\"#fff\" stroke-linejoin=\"miter\" /></g><g id=\"black-rook\" class=\"black rook\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M9 39h27v-3H9v3zM12.5 32l1.5-2.5h17l1.5 2.5h-20zM12 36v-4h21v4H12z\" stroke-linecap=\"butt\" /><path d=\"M14 29.5v-13h17v13H14z\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M14 16.5L11 14h23l-3 2.5H14zM11 14V9h4v2h5V9h5v2h5V9h4v5H11z\" stroke-linecap=\"butt\" /><path d=\"M12 35.5h21M13 31.5h19M14 29.5h17M14 16.5h17M11 14h23\" fill=\"none\" stroke=\"#fff\" stroke-width=\"1\" stroke-linejoin=\"miter\" /></g><g id=\"black-queen\" class=\"black queen\" fill=\"#000\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><g fill=\"#000\" stroke=\"none\"><circle cx=\"6\" cy=\"12\" r=\"2.75\" /><circle cx=\"14\" cy=\"9\" r=\"2.75\" /><circle cx=\"22.5\" cy=\"8\" r=\"2.75\" /><circle cx=\"31\" cy=\"9\" r=\"2.75\" /><circle cx=\"39\" cy=\"12\" r=\"2.75\" /></g><path d=\"M9 26c8.5-1.5 21-1.5 27 0l2.5-12.5L31 25l-.3-14.1-5.2 13.6-3-14.5-3 14.5-5.2-13.6L14 25 6.5 13.5 9 26zM9 26c0 2 1.5 2 2.5 4 1 1.5 1 1 .5 3.5-1.5 1-1.5 2.5-1.5 2.5-1.5 1.5.5 2.5.5 2.5 6.5 1 16.5 1 23 0 0 0 1.5-1 0-2.5 0 0 .5-1.5-1-2.5-.5-2.5-.5-2 .5-3.5 1-2 2.5-2 2.5-4-8.5-1.5-18.5-1.5-27 0z\" stroke-linecap=\"butt\" /><path d=\"M11 38.5a35 35 1 0 0 23 0\" fill=\"none\" stroke-linecap=\"butt\" /><path d=\"M11 29a35 35 1 0 1 23 0M12.5 31.5h20M11.5 34.5a35 35 1 0 0 22 0M10.5 37.5a35 35 1 0 0 24 0\" fill=\"none\" stroke=\"#fff\" /></g><g id=\"black-king\" class=\"black king\" fill=\"none\" fill-rule=\"evenodd\" stroke=\"#000\" stroke-width=\"1.5\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path d=\"M22.5 11.63V6\" stroke-linejoin=\"miter\" /><path d=\"M22.5 25s4.5-7.5 3-10.5c0 0-1-2.5-3-2.5s-3 2.5-3 2.5c-1.5 3 3 10.5 3 10.5\" fill=\"#000\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\" /><path d=\"M11.5 37c5.5 3.5 15.5 3.5 21 0v-7s9-4.5 6-10.5c-4-6.5-13.5-3.5-16 4V27v-3.5c-3.5-7.5-13-10.5-16-4-3 6 5 10 5 10V37z\" fill=\"#000\" /><path d=\"M20 8h5\" stroke-linejoin=\"miter\" /><path d=\"M32 29.5s8.5-4 6.03-9.65C34.15 14 25 18 22.5 24.5l.01 2.1-.01-2.1C20 18 9.906 14 6.997 19.85c-2.497 5.65 4.853 9 4.853 9M11.5 30c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0m-21 3.5c5.5-3 15.5-3 21 0\" stroke=\"#fff\" /></g><radialGradient id=\"check_gradient\" r=\"0.5\"><stop offset=\"0%\" stop-color=\"#ff0000\" stop-opacity=\"1.0\" /><stop offset=\"50%\" stop-color=\"#e70000\" stop-opacity=\"1.0\" /><stop offset=\"100%\" stop-color=\"#9e0000\" stop-opacity=\"0.0\" /></radialGradient></defs><rect x=\"7.5\" y=\"7.5\" width=\"375\" height=\"375\" fill=\"none\" stroke=\"#212121\" stroke-width=\"15\" /><g transform=\"translate(20, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(20, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M23.328 10.016q-1.742 0-2.414.398-.672.398-.672 1.36 0 .765.5 1.218.508.445 1.375.445 1.196 0 1.914-.843.727-.852.727-2.258v-.32zm2.867-.594v4.992h-1.437v-1.328q-.492.797-1.227 1.18-.734.375-1.797.375-1.343 0-2.14-.75-.79-.758-.79-2.024 0-1.476.985-2.226.992-.75 2.953-.75h2.016V8.75q0-.992-.656-1.531-.649-.547-1.829-.547-.75 0-1.46.18-.711.18-1.368.539V6.062q.79-.304 1.532-.453.742-.156 1.445-.156 1.898 0 2.836.984.937.985.937 2.985z\" /></g><g transform=\"translate(65, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(65, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.922 10.047q0-1.586-.656-2.485-.649-.906-1.79-.906-1.14 0-1.796.906-.649.899-.649 2.485 0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.789-.898.656-.906.656-2.492zm-4.89-3.055q.452-.781 1.14-1.156.695-.383 1.656-.383 1.594 0 2.586 1.266 1 1.265 1 3.328 0 2.062-1 3.328-.992 1.266-2.586 1.266-.96 0-1.656-.375-.688-.383-1.14-1.164v1.312h-1.446V2.258h1.445z\" /></g><g transform=\"translate(110, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(110, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.96 6v1.344q-.608-.336-1.226-.5-.609-.172-1.234-.172-1.398 0-2.172.89-.773.883-.773 2.485 0 1.601.773 2.492.774.883 2.172.883.625 0 1.234-.164.618-.172 1.227-.508v1.328q-.602.281-1.25.422-.64.14-1.367.14-1.977 0-3.14-1.242-1.165-1.242-1.165-3.351 0-2.14 1.172-3.367 1.18-1.227 3.227-1.227.664 0 1.296.14.633.134 1.227.407z\" /></g><g transform=\"translate(155, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(155, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 6.992V2.258h1.437v12.156h-1.437v-1.312q-.453.78-1.149 1.164-.687.375-1.656.375-1.586 0-2.586-1.266-.992-1.266-.992-3.328 0-2.063.992-3.328 1-1.266 2.586-1.266.969 0 1.656.383.696.375 1.149 1.156zm-4.899 3.055q0 1.586.649 2.492.656.898 1.797.898 1.14 0 1.796-.898.657-.906.657-2.492 0-1.586-.657-2.485-.656-.906-1.796-.906-1.141 0-1.797.906-.649.899-.649 2.485z\" /></g><g transform=\"translate(200, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(200, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.555 9.68v.703h-6.61q.094 1.484.89 2.265.806.774 2.235.774.828 0 1.602-.203.781-.203 1.547-.61v1.36q-.774.328-1.586.5-.813.172-1.649.172-2.093 0-3.32-1.22-1.219-1.218-1.219-3.296 0-2.148 1.157-3.406 1.164-1.266 3.132-1.266 1.766 0 2.79 1.14 1.03 1.134 1.03 3.087zm-1.438-.422q-.015-1.18-.664-1.883-.64-.703-1.703-.703-1.203 0-1.93.68-.718.68-.828 1.914z\" /></g><g transform=\"translate(245, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(245, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M25.285 2.258v1.195H23.91q-.773 0-1.078.313-.297.312-.297 1.125v.773h2.367v1.117h-2.367v7.633H21.09V6.781h-1.375V5.664h1.375v-.61q0-1.46.68-2.124.68-.672 2.156-.672z\" /></g><g transform=\"translate(290, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(290, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M24.973 9.937q0-1.562-.649-2.421-.64-.86-1.804-.86-1.157 0-1.805.86-.64.859-.64 2.421 0 1.555.64 2.415.648.859 1.805.859 1.164 0 1.804-.86.649-.859.649-2.414zm1.437 3.391q0 2.234-.992 3.32-.992 1.094-3.04 1.094-.757 0-1.429-.117-.672-.11-1.304-.344v-1.398q.632.344 1.25.508.617.164 1.257.164 1.414 0 2.118-.743.703-.734.703-2.226v-.711q-.446.773-1.141 1.156-.695.383-1.664.383-1.61 0-2.594-1.227-.984-1.226-.984-3.25 0-2.03.984-3.257.985-1.227 2.594-1.227.969 0 1.664.383t1.14 1.156V5.664h1.438z\" /></g><g transform=\"translate(335, 1) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(335, 375) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M26.164 9.133v5.281h-1.437V9.18q0-1.243-.485-1.86-.484-.617-1.453-.617-1.164 0-1.836.742-.672.742-.672 2.024v4.945h-1.445V2.258h1.445v4.765q.516-.789 1.211-1.18.703-.39 1.617-.39 1.508 0 2.282.938.773.93.773 2.742z\" /></g><g transform=\"translate(0, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(375, 335) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.754 26.996h2.578v-8.898l-2.805.562v-1.437l2.79-.563h1.578v10.336h2.578v1.328h-6.72z\" /></g><g transform=\"translate(0, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(375, 290) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M8.195 26.996h5.508v1.328H6.297v-1.328q.898-.93 2.445-2.492 1.555-1.57 1.953-2.024.758-.851 1.055-1.437.305-.594.305-1.164 0-.93-.657-1.516-.648-.586-1.695-.586-.742 0-1.57.258-.82.258-1.758.781v-1.593q.953-.383 1.781-.578.828-.196 1.516-.196 1.812 0 2.89.906 1.079.907 1.079 2.422 0 .72-.274 1.368-.265.64-.976 1.515-.196.227-1.243 1.313-1.046 1.078-2.953 3.023z\" /></g><g transform=\"translate(0, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(375, 245) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.434 22.035q1.132.242 1.765 1.008.64.766.64 1.89 0 1.727-1.187 2.672-1.187.946-3.375.946-.734 0-1.515-.149-.774-.14-1.602-.43V26.45q.656.383 1.438.578.78.196 1.632.196 1.485 0 2.258-.586.782-.586.782-1.703 0-1.032-.727-1.61-.719-.586-2.008-.586h-1.36v-1.297h1.423q1.164 0 1.78-.46.618-.47.618-1.344 0-.899-.64-1.375-.633-.485-1.82-.485-.65 0-1.391.141-.743.14-1.633.437V16.95q.898-.25 1.68-.375.788-.125 1.484-.125 1.797 0 2.844.82 1.046.813 1.046 2.204 0 .968-.554 1.64-.555.664-1.578.922z\" /></g><g transform=\"translate(0, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(375, 200) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M11.016 18.035L7.03 24.262h3.985zm-.414-1.375h1.984v7.602h1.664v1.312h-1.664v2.75h-1.57v-2.75H5.75v-1.523z\" /></g><g transform=\"translate(0, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(375, 155) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.719 16.66h6.195v1.328h-4.75v2.86q.344-.118.688-.172.343-.063.687-.063 1.953 0 3.094 1.07 1.14 1.07 1.14 2.899 0 1.883-1.171 2.93-1.172 1.039-3.305 1.039-.735 0-1.5-.125-.758-.125-1.57-.375v-1.586q.703.383 1.453.57.75.188 1.586.188 1.351 0 2.14-.711.79-.711.79-1.93 0-1.219-.79-1.93-.789-.71-2.14-.71-.633 0-1.266.14-.625.14-1.281.438z\" /></g><g transform=\"translate(0, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(375, 110) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10.137 21.863q-1.063 0-1.688.727-.617.726-.617 1.992 0 1.258.617 1.992.625.727 1.688.727 1.062 0 1.68-.727.624-.734.624-1.992 0-1.266-.625-1.992-.617-.727-1.68-.727zm3.133-4.945v1.437q-.594-.28-1.204-.43-.601-.148-1.195-.148-1.562 0-2.39 1.055-.82 1.055-.938 3.188.46-.68 1.156-1.04.696-.367 1.531-.367 1.758 0 2.774 1.07 1.023 1.063 1.023 2.899 0 1.797-1.062 2.883-1.063 1.086-2.828 1.086-2.024 0-3.094-1.547-1.07-1.555-1.07-4.5 0-2.766 1.312-4.406 1.313-1.649 3.524-1.649.593 0 1.195.117.61.118 1.266.352z\" /></g><g transform=\"translate(0, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(375, 65) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M6.25 16.66h7.5v.672L9.516 28.324H7.867l3.985-10.336H6.25z\" /></g><g transform=\"translate(0, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><g transform=\"translate(375, 20) scale(0.75, 0.75)\" fill=\"#e5e5e5\" stroke=\"#e5e5e5\"><path d=\"M10 22.785q-1.125 0-1.773.602-.641.601-.641 1.656t.64 1.656q.649.602 1.774.602t1.773-.602q.649-.61.649-1.656 0-1.055-.649-1.656-.64-.602-1.773-.602zm-1.578-.672q-1.016-.25-1.586-.945-.563-.695-.563-1.695 0-1.399.993-2.211 1-.813 2.734-.813 1.742 0 2.734.813.993.812.993 2.21 0 1-.57 1.696-.563.695-1.571.945 1.14.266 1.773 1.04.641.773.641 1.89 0 1.695-1.04 2.602-1.03.906-2.96.906t-2.969-.906Q6 26.738 6 25.043q0-1.117.64-1.89.641-.774 1.782-1.04zm-.578-2.492q0 .906.562 1.414.57.508 1.594.508 1.016 0 1.586-.508.578-.508.578-1.414 0-.906-.578-1.414-.57-.508-1.586-.508-1.023 0-1.594.508-.562.508-.562 1.414z\" /></g><rect x=\"15\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark a1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"330\" width=\"45\" height=\"45\" class=\"square light b1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark c1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"330\" width=\"45\" height=\"45\" class=\"square light d1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark e1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"330\" width=\"45\" height=\"45\" class=\"square light f1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"330\" width=\"45\" height=\"45\" class=\"square dark g1\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"330\" width=\"45\" height=\"45\" class=\"square light h1\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"285\" width=\"45\" height=\"45\" class=\"square light a2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark b2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"285\" width=\"45\" height=\"45\" class=\"square light c2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark d2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"285\" width=\"45\" height=\"45\" class=\"square light e2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark f2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"285\" width=\"45\" height=\"45\" class=\"square light g2\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"285\" width=\"45\" height=\"45\" class=\"square dark h2\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark a3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"240\" width=\"45\" height=\"45\" class=\"square light b3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark c3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"240\" width=\"45\" height=\"45\" class=\"square light d3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark e3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"240\" width=\"45\" height=\"45\" class=\"square light f3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"240\" width=\"45\" height=\"45\" class=\"square dark g3\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"240\" width=\"45\" height=\"45\" class=\"square light h3\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"195\" width=\"45\" height=\"45\" class=\"square light a4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark b4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"195\" width=\"45\" height=\"45\" class=\"square light c4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark d4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"195\" width=\"45\" height=\"45\" class=\"square light e4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark f4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"195\" width=\"45\" height=\"45\" class=\"square light g4\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"195\" width=\"45\" height=\"45\" class=\"square dark h4\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark a5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"150\" width=\"45\" height=\"45\" class=\"square light b5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark c5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"150\" width=\"45\" height=\"45\" class=\"square light d5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark e5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"150\" width=\"45\" height=\"45\" class=\"square light f5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"150\" width=\"45\" height=\"45\" class=\"square dark g5\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"150\" width=\"45\" height=\"45\" class=\"square light h5\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"105\" width=\"45\" height=\"45\" class=\"square light a6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark b6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"105\" width=\"45\" height=\"45\" class=\"square light c6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark d6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"105\" width=\"45\" height=\"45\" class=\"square light e6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark f6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"105\" width=\"45\" height=\"45\" class=\"square light g6\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"105\" width=\"45\" height=\"45\" class=\"square dark h6\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"15\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark a7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"60\" y=\"60\" width=\"45\" height=\"45\" class=\"square light b7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"105\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark c7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"150\" y=\"60\" width=\"45\" height=\"45\" class=\"square light d7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"195\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark e7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"240\" y=\"60\" width=\"45\" height=\"45\" class=\"square light f7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"285\" y=\"60\" width=\"45\" height=\"45\" class=\"square dark g7\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"330\" y=\"60\" width=\"45\" height=\"45\" class=\"square light h7\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"15\" y=\"15\" width=\"45\" height=\"45\" class=\"square light a8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"60\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark b8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"105\" y=\"15\" width=\"45\" height=\"45\" class=\"square light c8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"150\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark d8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"square light e8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"240\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark f8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"285\" y=\"15\" width=\"45\" height=\"45\" class=\"square light g8\" stroke=\"none\" fill=\"#ffce9e\" /><rect x=\"330\" y=\"15\" width=\"45\" height=\"45\" class=\"square dark h8\" stroke=\"none\" fill=\"#d18b47\" /><rect x=\"195\" y=\"15\" width=\"45\" height=\"45\" class=\"check\" fill=\"url(#check_gradient)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(15, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(60, 330)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 330)\" /><use href=\"#white-king\" xlink:href=\"#white-king\" transform=\"translate(195, 330)\" /><use href=\"#white-knight\" xlink:href=\"#white-knight\" transform=\"translate(285, 330)\" /><use href=\"#white-rook\" xlink:href=\"#white-rook\" transform=\"translate(330, 330)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(15, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(60, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(105, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(150, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(240, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(285, 285)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(330, 285)\" /><use href=\"#white-bishop\" xlink:href=\"#white-bishop\" transform=\"translate(105, 195)\" /><use href=\"#white-pawn\" xlink:href=\"#white-pawn\" transform=\"translate(195, 195)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(195, 150)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(105, 105)\" /><use href=\"#black-knight\" xlink:href=\"#black-knight\" transform=\"translate(240, 105)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(15, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(60, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(105, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(150, 60)\" /><use href=\"#white-queen\" xlink:href=\"#white-queen\" transform=\"translate(240, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(285, 60)\" /><use href=\"#black-pawn\" xlink:href=\"#black-pawn\" transform=\"translate(330, 60)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(15, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(105, 15)\" /><use href=\"#black-queen\" xlink:href=\"#black-queen\" transform=\"translate(150, 15)\" /><use href=\"#black-king\" xlink:href=\"#black-king\" transform=\"translate(195, 15)\" /><use href=\"#black-bishop\" xlink:href=\"#black-bishop\" transform=\"translate(240, 15)\" /><use href=\"#black-rook\" xlink:href=\"#black-rook\" transform=\"translate(330, 15)\" /></svg>"
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Masked Output"
      ],
      "metadata": {
        "id": "IcikeBVId31x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random boards and make sure legal moves are not masked and illegal moves are masked\n",
        "board = chess.Board()\n",
        "chess_helper = ChessHelper()\n",
        "while board.outcome() is None:\n",
        "  test_output = torch.randn((1, 73, 8, 8))\n",
        "  test_output = chess_helper.masker(test_output, board.fen())\n",
        "  is_finite = torch.isfinite(test_output)\n",
        "  for move in board.legal_moves:\n",
        "    # Get corresponding index in output tensor for move\n",
        "    channel_idx, row_idx, col_idx = chess_helper.move_to_index(board.turn, move)\n",
        "    # See if the legal move is improperly masked\n",
        "    assert(is_finite[0, channel_idx, row_idx, col_idx])\n",
        "  # See if illegal moves are not masked\n",
        "  assert(torch.sum(is_finite) == len(list(board.legal_moves)))\n",
        "  rand_legal_move = np.random.choice(list(board.legal_moves))\n",
        "  board.push(rand_legal_move)"
      ],
      "metadata": {
        "id": "_SucGNlknQJN"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.randn(1, 73, 8, 8)\n",
        "fen = chess.STARTING_FEN\n",
        "\n",
        "masker_test = ChessHelper()\n",
        "masked = masker_test.masker(output, fen)\n",
        "\n",
        "# Legal moves\n",
        "print(\"Legal move indices:\", (masked != float('-inf')).nonzero())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuS8sgmud11n",
        "outputId": "69a59b91-5ed8-401b-d1e5-56ef66152d46"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legal move indices: tensor([[ 0,  7,  6,  0],\n",
            "        [ 0,  7,  6,  1],\n",
            "        [ 0,  7,  6,  2],\n",
            "        [ 0,  7,  6,  3],\n",
            "        [ 0,  7,  6,  4],\n",
            "        [ 0,  7,  6,  5],\n",
            "        [ 0,  7,  6,  6],\n",
            "        [ 0,  7,  6,  7],\n",
            "        [ 0,  8,  6,  0],\n",
            "        [ 0,  8,  6,  1],\n",
            "        [ 0,  8,  6,  2],\n",
            "        [ 0,  8,  6,  3],\n",
            "        [ 0,  8,  6,  4],\n",
            "        [ 0,  8,  6,  5],\n",
            "        [ 0,  8,  6,  6],\n",
            "        [ 0,  8,  6,  7],\n",
            "        [ 0, 56,  7,  1],\n",
            "        [ 0, 56,  7,  6],\n",
            "        [ 0, 57,  7,  1],\n",
            "        [ 0, 57,  7,  6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running an Episode"
      ],
      "metadata": {
        "id": "X9dTQF2WHhHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Credit: https://github.com/suragnair/alpha-zero-general/blob/master/Coach.py\n",
        "def execute_episode(dqn, epsilon):\n",
        "  \"\"\"\n",
        "  This function executes one episode of self-play, starting with player 1.\n",
        "  As the game is played, each turn is added as a training example to\n",
        "  trainExamples. The game is played till the game ends. After the game\n",
        "  ends, the outcome of the game is used to assign values to each example\n",
        "  in trainExamples.\n",
        "\n",
        "  Output:\n",
        "    white_train_examples: a list of examples of the form (state, action, next state, reward, terminal)\n",
        "                      terminal is 1 if game ends on the turn, else 0\n",
        "                      reward is +1 if white wins, -1 if black wins, 0 if draw or not\n",
        "                      winning\n",
        "    black_train_examples: same as white_train_examples but for black\n",
        "  \"\"\"\n",
        "  board = chess.Board()\n",
        "  chess_helper = ChessHelper(step_history=0)\n",
        "  # Containers to store training examples in format (turn, state, action, next state, terminal, reward)\n",
        "  white_train_examples = []\n",
        "  black_train_examples = []\n",
        "\n",
        "  while True:\n",
        "    curr_state = board.fen()\n",
        "    curr_input = chess_helper.board_state_to_input(curr_state).to(device)\n",
        "    # Calculating best move and moving board\n",
        "    output = dqn(curr_input)\n",
        "    output = chess_helper.masker(output, curr_state)\n",
        "\n",
        "    # Epsilon-Greedy policy\n",
        "    unif = torch.rand(1)\n",
        "    # Random policy; choose random move\n",
        "    if unif < epsilon:\n",
        "      chosen_move = np.random.choice(list(board.legal_moves))\n",
        "      move_indices = chess_helper.move_to_index(board.turn, chosen_move)\n",
        "    # Greedy policy; get indices corresponding to move with optimal Q-value\n",
        "    else:\n",
        "      move_indices = chess_helper.output_to_optimal_indices(output, board.fen())\n",
        "      from_square, to_square, promotion = chess_helper.indices_to_move(board.fen(), *move_indices)\n",
        "      chosen_move = chess.Move(from_square, to_square, promotion[0])\n",
        "      # Error catcher\n",
        "      if chosen_move not in board.legal_moves:\n",
        "        print('board fen', board.fen())\n",
        "        raise Exception('\\nSomething wrong in greedy policy or masker')\n",
        "\n",
        "    # Executing chosen move on board\n",
        "    board.push(chosen_move)\n",
        "    next_state = board.fen()\n",
        "    # TODO: change board_state_to_input to concat_history\n",
        "    next_input = chess_helper.board_state_to_input(next_state)\n",
        "\n",
        "    # Saving training example in different containers because different rewards will be given\n",
        "    outcome = board.outcome()\n",
        "    # Reversing board turn because next move has already been pushed\n",
        "    turn = 1 - board.turn\n",
        "    # If game continues then add to train examples\n",
        "    if (outcome is None):\n",
        "      train_example = Transition(turn, curr_input, move_indices, next_state, next_input, 0, None)\n",
        "      if turn:\n",
        "        white_train_examples.append(train_example)\n",
        "      else:\n",
        "        black_train_examples.append(train_example)\n",
        "    # If game ends then give out rewards\n",
        "    else:\n",
        "      train_example = Transition(turn, curr_input, move_indices, next_state, next_input, 1, None)\n",
        "      if outcome.winner == chess.WHITE:\n",
        "        white_train_examples.append(train_example)\n",
        "        white_train_examples = [example[:-1] + (1,) for example in white_train_examples]\n",
        "        black_train_examples = [example[:-1] + (0,) for example in black_train_examples]\n",
        "      elif outcome.winner == chess.BLACK:\n",
        "        black_train_examples.append(train_example)\n",
        "        white_train_examples = [example[:-1] + (0,) for example in white_train_examples]\n",
        "        black_train_examples = [example[:-1] + (-1,) for example in black_train_examples]\n",
        "      # Draw\n",
        "      else:\n",
        "        if turn:\n",
        "          white_train_examples.append(train_example)\n",
        "        else:\n",
        "          black_train_examples.append(train_example)\n",
        "        white_train_examples = [example[:-1] + (0,) for example in white_train_examples]\n",
        "        black_train_examples = [example[:-1] + (0,) for example in black_train_examples]\n",
        "\n",
        "      # Memory management\n",
        "      del board\n",
        "\n",
        "      return white_train_examples, black_train_examples"
      ],
      "metadata": {
        "id": "p7pOtvIYDKRV"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update(dqn, target_dqn, rm, optimizer, criterion=nn.SmoothL1Loss(), gamma=0.99, tau=1e-3):\n",
        "  \"\"\"\n",
        "  Updates policy network using replay memory and soft updates target network.\n",
        "  Gamma is the discount factor in the TD loss.\n",
        "  Tau is the update rate of the target network.\n",
        "  \"\"\"\n",
        "  # Sampling from replay memory\n",
        "  transitions = rm.sample()\n",
        "  batch = Transition(*zip(*transitions))\n",
        "  # Collecting batched data\n",
        "  turns = torch.tensor(batch.turn, dtype=bool).to(device)\n",
        "  states = torch.cat(batch.state, dim=0).to(device)\n",
        "  actions = torch.tensor(batch.action).to(device)\n",
        "  next_fens = batch.next_fen\n",
        "  next_states = torch.cat(batch.next_state, dim=0).to(device)\n",
        "  terminals = torch.tensor(batch.terminal).to(device)\n",
        "  rewards = torch.tensor(batch.reward).to(device)\n",
        "\n",
        "  # Double Q-learning\n",
        "  with torch.no_grad():\n",
        "    # Masking output of next state Q-values\n",
        "    next_outputs = dqn(next_states)\n",
        "    chess_helper = ChessHelper()\n",
        "    for i in range(len(next_fens)):\n",
        "      next_fen = next_fens[i]\n",
        "      next_output = next_outputs[i, :, :, :].unsqueeze(0)\n",
        "      next_output = chess_helper.masker(next_output, next_fen)\n",
        "      next_outputs[i, :, :, :] = next_output.squeeze(0)\n",
        "    B, C, H, W = next_outputs.shape\n",
        "    # Getting indices from policy DQN\n",
        "    flat_idx = torch.zeros((B), dtype=torch.int64).to(device)\n",
        "    # If current turn is white, then we want to take argmin of next state and vice versa (https://ai.stackexchange.com/questions/6573/how-can-both-agents-know-the-terminal-reward-in-self-play-reinforcement-learning)\n",
        "    white_flat_idx = next_outputs[turns].flatten(start_dim=1).argmin(dim=1)\n",
        "    black_flat_idx = next_outputs[~turns].flatten(start_dim=1).argmax(dim=1)\n",
        "    flat_idx[turns] = white_flat_idx\n",
        "    flat_idx[~turns] = black_flat_idx\n",
        "    multi_index = torch.unravel_index(flat_idx, (C, H, W))\n",
        "    batch_indices = torch.arange(next_outputs.shape[0])\n",
        "    # Indexing target DQN to get next state Q-values\n",
        "    target_next_outputs = target_dqn(next_states)\n",
        "    q_target = next_outputs[batch_indices, multi_index[0], multi_index[1], multi_index[2]].detach()\n",
        "    y_j = rewards + gamma * q_target * (1 - terminals)\n",
        "\n",
        "  # Calculating current state Q-values\n",
        "  curr_outputs = dqn(states)\n",
        "  q_eval = curr_outputs[batch_indices, actions[:, 0], actions[:, 1], actions[:, 2]]\n",
        "  # TD loss\n",
        "  loss = criterion(q_eval, y_j)\n",
        "\n",
        "  # Optimizer\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # Updating target DQN\n",
        "  soft_update(dqn, target_dqn, tau)\n",
        "\n",
        "  return loss.detach()"
      ],
      "metadata": {
        "id": "vFeMguMHYyp4"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def soft_update(dqn, target_dqn, tau):\n",
        "    \"\"\"\n",
        "    Soft updates target network\n",
        "    \"\"\"\n",
        "    for eval_param, target_param in zip(\n",
        "        dqn.parameters(), target_dqn.parameters()\n",
        "    ):\n",
        "        target_param.data.copy_(\n",
        "            tau * eval_param.data + (1.0 - tau) * target_param.data\n",
        "        )"
      ],
      "metadata": {
        "id": "_FUuu-UJQNRx"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "AgplYnWjLSd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting checkpoint path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/Colab Notebooks/Math_M148_checkpoints'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0cM0XzMf28I",
        "outputId": "1db2c6ba-f6fc-4543-fb11-a82201fb1f3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_info(num_iters, training_info, checkpoint_path):\n",
        "  fig, ax = plt.subplots(3, 2, figsize=(12,12), constrained_layout=True)\n",
        "  iterations = np.arange(num_iters)\n",
        "  ax[0,0].plot(iterations, training_info['losses'])\n",
        "  ax[0,1].plot(iterations, training_info['epsilons'])\n",
        "  ax[1,0].plot(iterations, training_info['time_per_iter'] / 60)\n",
        "  ax[1,1].plot(iterations, training_info['size_of_rm'])\n",
        "  ax[2,0].plot(iterations, training_info['model_updates'])\n",
        "  titles = ['Training Loss', 'Epsilon', 'Time per Iteration', 'Size of Replay Memory', 'Cumulative Model Updates']\n",
        "  y_labels = ['Loss', 'Epsilon', 'Minutes', 'Number of Examples', 'Count']\n",
        "  idx = 0\n",
        "  for i in range(3):\n",
        "    for j in range(2):\n",
        "      if i == 2 and j == 1:\n",
        "        break\n",
        "      ax[i, j].set(title=titles[idx], xlabel='Iterations', ylabel=y_labels[idx])\n",
        "      idx += 1\n",
        "\n",
        "  fig.savefig(os.path.join(checkpoint_path, \"training_info.png\"), dpi=300)\n",
        "\n",
        "  # Memory management\n",
        "  plt.close(fig)"
      ],
      "metadata": {
        "id": "o613bMPDOOQr"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(iters, epsilon, criterion, rm, dqn, target_dqn, opp_dqn, optimizer,\n",
        "                    training_info, checkpoint_file_path):\n",
        "  checkpoint = {\n",
        "              'iters': iters + 1,\n",
        "              'epsilon': epsilon,\n",
        "              'criterion': criterion,\n",
        "              'rm': rm,\n",
        "              'dqn_state_dict': dqn.state_dict(),\n",
        "              'target_dqn_state_dict': target_dqn.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'training_info': training_info\n",
        "  }\n",
        "  torch.save(checkpoint, checkpoint_file_path)"
      ],
      "metadata": {
        "id": "vbEFkGejbe4H"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_file_path):\n",
        "  chk = torch.load(checkpoint_file_path, weights_only=False)\n",
        "\n",
        "  start_iters = chk['iters']\n",
        "  epsilon = chk['epsilon']\n",
        "  criterion = chk['criterion']\n",
        "  rm = ReplayMemory(chk['rm'].capacity, chk['rm'].batch_size)\n",
        "  rm.memory = chk['rm'].memory\n",
        "  dqn.load_state_dict(chk['dqn_state_dict'])\n",
        "  target_dqn.load_state_dict(chk['target_dqn_state_dict'])\n",
        "  optimizer.load_state_dict(chk['optimizer_state_dict'])\n",
        "  training_info = chk['training_info']\n",
        "\n",
        "  return start_iters, epsilon, criterion, rm, dqn, target_dqn, optimizer, training_info"
      ],
      "metadata": {
        "id": "BBEMUH3Q0ntX"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compete(dqn, opp_dqn, num_games=100, epsilon_end=0.05):\n",
        "  dqn.eval()\n",
        "  opp_dqn.eval()\n",
        "  board = chess.Board()\n",
        "  chess_helper = ChessHelper(step_history=0)\n",
        "  players = [dqn, opp_dqn]\n",
        "  # Counting dqn wins, opp_dqn wins, and draws\n",
        "  outcomes = np.zeros(3).astype(int)\n",
        "\n",
        "  for game in range(num_games):\n",
        "    board = chess.Board()\n",
        "    chess_helper = ChessHelper()\n",
        "    player_turn = random.randint(0, 1)\n",
        "    while board.outcome() is None:\n",
        "      curr_state = board.fen()\n",
        "      curr_input = chess_helper.board_state_to_input(fen).to(device)\n",
        "\n",
        "      # Calculating best move and moving board\n",
        "      with torch.no_grad():\n",
        "        output = players[player_turn](curr_input)\n",
        "        masked_output = chess_helper.masker(output, curr_state)\n",
        "\n",
        "      # Epsilon-Greedy policy\n",
        "      unif = torch.rand(1)\n",
        "      # Random policy; choose random move\n",
        "      if unif < epsilon_end:\n",
        "        chosen_move = np.random.choice(list(board.legal_moves))\n",
        "        move_indices = chess_helper.move_to_index(board.turn, chosen_move)\n",
        "      # Greedy policy; get indices corresponding to move with optimal Q-value\n",
        "      else:\n",
        "        move_indices = chess_helper.output_to_optimal_indices(masked_output, board.fen())\n",
        "        from_square, to_square, promotion = chess_helper.indices_to_move(board.fen(), *move_indices)\n",
        "        chosen_move = chess.Move(from_square, to_square, promotion[0])\n",
        "\n",
        "      # Executing chosen move on board\n",
        "      board.push(chosen_move)\n",
        "\n",
        "      # Switching player turn\n",
        "      player_turn = 1 - player_turn\n",
        "    winning_player = 1 - player_turn\n",
        "    if board.outcome().winner is None:\n",
        "      outcomes[2] += 1\n",
        "    else:\n",
        "      outcomes[winning_player] += 1\n",
        "  return tuple(outcomes)"
      ],
      "metadata": {
        "id": "f-xbEVJ_gT0g"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Choosing Epsilon Decay"
      ],
      "metadata": {
        "id": "xIwEcvxnN9cS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code from https://stackoverflow.com/questions/48583396/q-learning-epsilon-greedy-update\n",
        "eps_start = 1.0\n",
        "eps_min = 0.05\n",
        "eps_decay = 0.995\n",
        "epochs = 1000\n",
        "pct = 0\n",
        "df = np.zeros(epochs)\n",
        "stop = 0\n",
        "for i in range(epochs):\n",
        "    if i == 0:\n",
        "        df[i] = eps_start\n",
        "    else:\n",
        "        df[i] = df[i-1] * eps_decay\n",
        "        if df[i] <= eps_min:\n",
        "            print(i)\n",
        "            stop = i\n",
        "            break\n",
        "\n",
        "print(\"With this parameter you will stop epsilon decay after {}% of training\".format(stop/epochs*100))\n",
        "plt.plot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "JMuwKN_9Nh-V",
        "outputId": "6bec2442-0cdc-4337-bc95-da23565775df"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "598\n",
            "With this parameter you will stop epsilon decay after 59.8% of training\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Parameters"
      ],
      "metadata": {
        "id": "ZKr3ofoHOpZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_iters = 0           # Starting iteration is 0 if not loading from checkpoing\n",
        "num_iters = 1000          # Number of iterations to run for\n",
        "num_eps = 50              # Number of episodes to execute during iteration\n",
        "num_games = 40            # Number of games to play to see if new model will be accepted\n",
        "update_threshold = 0.6    # Percent of games to win to update opponent model\n",
        "epsilon = 1.0             # Probability of choosing random move for epsilon-greedy policy\n",
        "epsilon_end = 0.05\n",
        "epsilon_decay = 0.995\n",
        "gamma = 0.99              # Discount factor for TD loss\n",
        "tau = 1e-3                # Soft update parameter for target model\n",
        "lr = 1e-3                 # Learning rate for optimizer\n",
        "batch_size = 64           # Batch size of replay memory\n",
        "criterion = nn.SmoothL1Loss()\n",
        "\n",
        "input_channels = 19\n",
        "dqn = DQN(input_channels).to(device)\n",
        "target_dqn = DQN(input_channels).to(device)\n",
        "target_dqn.load_state_dict(dqn.state_dict())\n",
        "\n",
        "optimizer = optim.AdamW(dqn.parameters(), lr=lr)\n",
        "rm = ReplayMemory(capacity=100000, batch_size=batch_size)\n",
        "\n",
        "# Containers to store data\n",
        "training_info = {\n",
        "  'time_per_iter': np.full(num_iters, np.nan),\n",
        "  'losses': np.full(num_iters, np.nan),\n",
        "  'epsilons': np.full(num_iters, np.nan),\n",
        "  'size_of_rm': np.full(num_iters, np.nan),\n",
        "  'model_updates': np.full(num_iters, np.nan)\n",
        "}"
      ],
      "metadata": {
        "id": "Rj3JOWwmLPuy"
      },
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Training"
      ],
      "metadata": {
        "id": "xytjrD0XLivi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_prev_checkpoint = True\n",
        "\n",
        "if not load_prev_checkpoint:\n",
        "  # Warmup replay memory before training\n",
        "  warmup_size = rm.capacity * 0.1\n",
        "  pbar = tqdm(total=warmup_size)\n",
        "  while len(rm) < warmup_size:\n",
        "    start_len = len(rm)\n",
        "    white_train_examples, black_train_examples = execute_episode(dqn, epsilon=1)\n",
        "    rm.extend(white_train_examples)\n",
        "    rm.extend(black_train_examples)\n",
        "    pbar.update(len(rm) - start_len)\n",
        "  pbar.close()\n",
        "else:\n",
        "  (start_iters, epsilon, criterion, rm,\n",
        "   dqn, target_dqn, optimizer, training_info) = load_checkpoint(os.path.join(checkpoint_path, 'checkpoint_latest.pth'))"
      ],
      "metadata": {
        "id": "p8Z2tYx8Vnjs"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for iters in tqdm(range(start_iters, num_iters)):\n",
        "  start_time = time.time()\n",
        "  dqn.train()\n",
        "  # Saving DQN model before training so we can use it to compare to new model\n",
        "  opp_dqn = DQN(input_channels).to(device)\n",
        "  opp_dqn.load_state_dict(dqn.state_dict())\n",
        "  # Execute set number of episodes and add to replay buffer\n",
        "  for eps in range(num_eps):\n",
        "    white_train_examples, black_train_examples = execute_episode(dqn, epsilon)\n",
        "    rm.extend(white_train_examples)\n",
        "    rm.extend(black_train_examples)\n",
        "  training_info['size_of_rm'][iters] = len(rm)\n",
        "\n",
        "  # Call update to model\n",
        "  loss = update(dqn, target_dqn, rm, optimizer, criterion=criterion, gamma=gamma, tau=tau)\n",
        "  training_info['losses'][iters] = loss\n",
        "\n",
        "  # Decrease epsilon\n",
        "  epsilon = max(epsilon * epsilon_decay, epsilon_end)\n",
        "  training_info['epsilons'][iters] = epsilon\n",
        "\n",
        "  dqn_wins, opp_dqn_wins, draws = compete(dqn, opp_dqn, num_games=num_games, epsilon_end=epsilon_end)\n",
        "  # Pit model against opp_model and keep updates from training if greater than a specified win rate\n",
        "  if dqn_wins + opp_dqn_wins == 0 or float(dqn_wins) / (dqn_wins + opp_dqn_wins) < update_threshold:\n",
        "    dqn.load_state_dict(opp_dqn.state_dict())\n",
        "    if iters == 0:\n",
        "      training_info['model_updates'][iters] = 0\n",
        "    else:\n",
        "      training_info['model_updates'][iters] = training_info['model_updates'][iters - 1]\n",
        "  else:\n",
        "    checkpoint_file_path = os.path.join(checkpoint_path, 'checkpoint_best.pth')\n",
        "    save_checkpoint(iters, epsilon, criterion, rm, dqn, target_dqn, optimizer, training_info, checkpoint_file_path)\n",
        "    if iters == 0:\n",
        "      training_info['model_updates'][iters] = 0\n",
        "    else:\n",
        "      training_info['model_updates'][iters] = training_info['model_updates'][iters - 1] + 1\n",
        "\n",
        "  # Tracking time to run an iteration\n",
        "  end_time = time.time()\n",
        "  training_info['time_per_iter'][iters] = end_time - start_time\n",
        "\n",
        "  # Checkpoint model, optimizer, and replay buffer\n",
        "  if (iters+1) % 5 == 0:\n",
        "    checkpoint_file_path = os.path.join(checkpoint_path, 'checkpoint_latest.pth')\n",
        "    save_checkpoint(iters, epsilon, criterion, rm, dqn, target_dqn, optimizer, training_info, checkpoint_file_path)\n",
        "    plot_training_info(num_iters, training_info, checkpoint_path)"
      ],
      "metadata": {
        "id": "4sCt1QStQvzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b8dc4d-62ba-4dc1-a409-4d7ffeccd4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 3/975 [08:36<46:34:00, 172.47s/it]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GEFhnA2nWclf",
        "E19p18imJOkm"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}